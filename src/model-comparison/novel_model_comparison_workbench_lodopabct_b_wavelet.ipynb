{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I : Global includes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Uncomment to disable GPU usage.\n",
    "# This is required for some models like Pridnet which has too many traininable parameters\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "import data_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II : Loading test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_lodopab_ct import get_validation_dataloader\n",
    "noisy_dataset = get_validation_dataloader(\"../../../../Dataset/LoDoPaB-CT/ground_truth_validation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image_from_patches(patches, num_patches_per_row):\n",
    "    patch_size = patches.shape[1]  # Assuming square patches\n",
    "    num_patches = patches.shape[0]\n",
    "\n",
    "    # Calculate the number of rows\n",
    "    num_patches_per_col = num_patches // num_patches_per_row\n",
    "\n",
    "    # Initialize an empty image to store the reconstructed result\n",
    "    reconstructed_image = np.zeros((num_patches_per_col * patch_size, num_patches_per_row * patch_size))\n",
    "\n",
    "    # Reshape the patches into a 2D array\n",
    "    patches_2d = patches.reshape((num_patches_per_col, num_patches_per_row, patch_size, patch_size))\n",
    "\n",
    "    # Reconstruct the image by placing each patch in its corresponding position\n",
    "    for i in range(num_patches_per_col):\n",
    "        for j in range(num_patches_per_row):\n",
    "            reconstructed_image[i * patch_size:(i + 1) * patch_size, j * patch_size:(j + 1) * patch_size] = patches_2d[i, j]\n",
    "\n",
    "    return np.expand_dims(reconstructed_image, axis=-1)\n",
    "\n",
    "noisy_array = [None] * 28\n",
    "print(len(noisy_dataset))\n",
    "for i, data in enumerate(noisy_dataset):\n",
    "    noisy_array[i] = reconstruct_image_from_patches(torch.squeeze(data[i], axis=0), 8)\n",
    "    if i == 28:\n",
    "        break\n",
    "noisy_array = np.array(noisy_array)\n",
    "print(noisy_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the noisy / ground truth image pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_importer import denormalize, trunc\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for i, data in enumerate(noisy_array):\n",
    "        plt.imshow(trunc(denormalize(data)), vmin=-160.0, vmax=240.0, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III : Setup for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "def inference_single_image(model, noisy_image):\n",
    "    input_image = np.expand_dims(noisy_image, axis=0)\n",
    "    predicted_image = model.predict(input_image)\n",
    "    a = np.abs(np.min(predicted_image))\n",
    "    b = np.max(predicted_image)\n",
    "    \n",
    "    #predicted_image = predicted_image * (b - a) + a\n",
    "    return predicted_image[0]\n",
    "\n",
    "def inference_batch_images(model, noisy_images):\n",
    "    input_image = noisy_images\n",
    "\n",
    "    predicted_image = model.predict(input_image).astype(np.float64)\n",
    "    return predicted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.expand_dims(np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]), axis=-1)\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from metrics import compute_SSIM, compute_PSNR\n",
    "from skimage.metrics import mean_squared_error  as mse\n",
    "\n",
    "def calculate_psnr(original_image, reconstructed_image,range=400):\n",
    "    return peak_signal_noise_ratio(original_image, reconstructed_image,data_range=range) \n",
    "\n",
    "    psnr_value = peak_signal_noise_ratio(original_image, reconstructed_image, data_range=240+160)\n",
    "    return psnr_value\n",
    "\n",
    "def calculate_ssim(original_image, reconstructed_image, range=400.0):    \n",
    "    ssim_value = ssim(original_image.astype(np.int16), reconstructed_image.astype(np.int16), win_size=11, channel_axis=2, data_range=range)\n",
    "    return ssim_value\n",
    "\n",
    "def calculate_rmse(original_image, reconstructed_image):\n",
    "    return mse(original_image, reconstructed_image)\n",
    "\n",
    "def visualize_predictions(model, X_test,  n, predictions, model_name):\n",
    "    random_numbers = list(range(n)) # not very random\n",
    "    for i in random_numbers:\n",
    "        gt_image= X_test[i].astype(np.float16)\n",
    "        predicted_image = predictions[i].astype(np.float16)\n",
    "\n",
    "        if predicted_image.shape[-1] == 3:\n",
    "            predicted_image = rgb2gray(predicted_image)\n",
    "                                \n",
    "            \n",
    "        psnr_recon =  calculate_psnr(trunc(denormalize(gt_image)), trunc(denormalize(predicted_image)))\n",
    "        ssim_recon = calculate_ssim(trunc(denormalize(gt_image)),  trunc(denormalize(predicted_image)))\n",
    "        rmse_recon = calculate_rmse(trunc(denormalize(gt_image)),  trunc(denormalize(predicted_image)))\n",
    "        \n",
    "        psnr_recon = round(psnr_recon, 4)\n",
    "        ssim_recon = round(ssim_recon, 4)\n",
    "        rmse_recon = round(rmse_recon, 4)\n",
    "        \n",
    "        f, axarr = plt.subplots(1,2, figsize=(21,21))\n",
    "\n",
    "        axarr[0].imshow(trunc(denormalize(gt_image)), cmap='gray', vmin=-160.0, vmax=240.0)\n",
    "        axarr[0].set_title(\"QD Image\")\n",
    "        axarr[0].set_axis_off()\n",
    "        axarr[1].imshow(trunc(denormalize(predicted_image)),  cmap='gray', vmin=-160.0, vmax=240.0)\n",
    "        axarr[1].set_title(\"{} Predicted Image : PSNR={}\\nSSIM={}\\nRMSE={}\".format(model_name, psnr_recon, ssim_recon, rmse_recon))\n",
    "        axarr[1].set_axis_off()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "\n",
    "def get_average_metrics(predicted_images,  _noisy_array):\n",
    "    psnr_original_mean = 0\n",
    "    psnr_prediction_mean = 0\n",
    "\n",
    "    ssim_original_mean = 0\n",
    "    ssim_prediction_mean = 0\n",
    "\n",
    "    mse_original_mean = 0\n",
    "    mse_prediction_mean = 0\n",
    "\n",
    "    i = 0\n",
    "    for  gt_img, predicted_img in zip(noisy_array, predicted_images):\n",
    "        predicted_img=  predicted_images[i]\n",
    "        if predicted_img.shape[-1] == 3:\n",
    "            predicted_img = rgb2gray(predicted_img)\n",
    "            \n",
    "        psnr_recon =  calculate_psnr(trunc(denormalize(gt_img)), trunc(denormalize(predicted_img)))\n",
    "        ssim_recon = calculate_ssim(trunc(denormalize(gt_img)),  trunc(denormalize(predicted_img)))\n",
    "        rmse_recon = calculate_rmse(trunc(denormalize(gt_img)),  trunc(denormalize(predicted_img)))\n",
    "\n",
    "        psnr_prediction_mean += psnr_recon\n",
    "        \n",
    "        ssim_prediction_mean += ssim_recon\n",
    "\n",
    "        mse_prediction_mean += rmse_recon\n",
    "        \n",
    "        i = i + 1        \n",
    "    \n",
    "    psnr_prediction_mean/=noisy_array.shape[0]\n",
    "\n",
    "    ssim_prediction_mean/=noisy_array.shape[0]\n",
    "\n",
    "    mse_prediction_mean/=noisy_array.shape[0]\n",
    "    \n",
    "    print(\"Predicted average gt-predicted PSNR ->\", psnr_prediction_mean)\n",
    "\n",
    "    print(\"Predicted average gt-predicted SSIM ->\", ssim_prediction_mean)\n",
    "\n",
    "    print(\"Predicted average gt-predicted MSE->\", mse_prediction_mean)\n",
    "    \n",
    "    return round(psnr_prediction_mean, 4), round(ssim_prediction_mean, 4), round(mse_prediction_mean, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV : Evaluation of each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 : Hformer (for base reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../denoising-models/hformer_vit/model/')\n",
    "sys.path.append('../denoising-models/hformer_vit/')\n",
    "from hformer_model_extended import get_hformer_model, PatchExtractor\n",
    "\n",
    "hformer_model = get_hformer_model(num_channels_to_be_generated=64, name=\"hformer_model_extended\")\n",
    "hformer_model.build(input_shape=(None, 64, 64, 1))\n",
    "hformer_model.load_weights('../denoising-models/hformer_vit/test/experiments/full_dataset/hformer_64_channel_custom_loss_epochs_48.h5')\n",
    "print('Model summary : ')\n",
    "print(hformer_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image_from_patches(patches, num_patches_per_row):\n",
    "    patch_size = patches.shape[1]  # Assuming square patches\n",
    "    num_patches = patches.shape[0]\n",
    "\n",
    "    # Calculate the number of rows\n",
    "    num_patches_per_col = num_patches // num_patches_per_row\n",
    "\n",
    "    # Initialize an empty image to store the reconstructed result\n",
    "    reconstructed_image = np.zeros((num_patches_per_col * patch_size, num_patches_per_row * patch_size))\n",
    "\n",
    "    # Reshape the patches into a 2D array\n",
    "    patches_2d = patches.reshape((num_patches_per_col, num_patches_per_row, patch_size, patch_size))\n",
    "    # Reconstruct the image by placing each patch in its corresponding position\n",
    "\n",
    "    for i in range(num_patches_per_col):\n",
    "        for j in range(num_patches_per_row):\n",
    "            reconstructed_image[i * patch_size:(i + 1) * patch_size, j * patch_size:(j + 1) * patch_size] = patches_2d[i, j]\n",
    "\n",
    "    return np.expand_dims(reconstructed_image, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predictions\n",
    "patch_extractor = PatchExtractor(patch_size=64, stride=64, name=\"patch_extractor\")\n",
    "noisy_image_patches_array = patch_extractor(noisy_array)\n",
    "\n",
    "hformer_prediction_patches = hformer_model.predict(noisy_image_patches_array)\n",
    "hformer_predictions = np.expand_dims(reconstruct_image_from_patches(hformer_prediction_patches[0:64], 8), axis=0)\n",
    "\n",
    "for i in range(1, int(hformer_prediction_patches.shape[0] / 64)): \n",
    "    reconstructed_image = reconstruct_image_from_patches(hformer_prediction_patches[i * 64 : i * 64 + 64], num_patches_per_row=8)\n",
    "    reconstructed_image = np.expand_dims(reconstructed_image, axis=0)\n",
    "\n",
    "    hformer_predictions = np.append(hformer_predictions, reconstructed_image, axis=0)\n",
    "visualize_predictions(hformer_predictions, noisy_array,  len(noisy_array), hformer_predictions, \"hformer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 : XB Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "sys.path.append('../denoising-models/novel_model/')\n",
    "from xb_denoiser_with_hf_conv import XModel \n",
    "x_model = XModel(num_channels=1)\n",
    "x_model.load_state_dict(torch.load('../denoising-models/novel_model_weights/xb_hf_model_889.pth'))\n",
    "x_model.eval()\n",
    "print('Model summary : ')\n",
    "print(summary(x_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction images.\n",
    "from pytorch_wavelets import DTCWTForward, DTCWTInverse\n",
    "dwt = DTCWTForward(J=3).cuda()\n",
    "idwt = DTCWTInverse().cuda()\n",
    "\n",
    "x_model_prediction_patches = []\n",
    "\n",
    "for img in noisy_array:\n",
    "    img_tensor = torch.from_numpy(np.expand_dims(img, axis=-0)).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_tensor = x_model(img_tensor)\n",
    "        _ot = output_tensor\n",
    "        output_tensor = output_tensor.cpu().numpy()\n",
    "\n",
    "\n",
    "        _ot = torch.transpose(_ot, 1, 3)\n",
    "        noisy = torch.from_numpy(np.expand_dims(img, axis=-1).astype(np.float32)).to('cuda')\n",
    "        noisy = torch.transpose(noisy, 1, 3)\n",
    "        noisy = torch.transpose(noisy, 0, 2)\n",
    "\n",
    "        print('ot shape : ', _ot.shape, ' noisy shape : ', noisy.shape)\n",
    "\n",
    "\n",
    "        prediction_approx, prediction_high_freq = dwt(_ot.cuda())\n",
    "        prediction_high_freq_low, prediction_high_freq_mid, prediction_high_freq_coarse = prediction_high_freq[0], prediction_high_freq[1], prediction_high_freq[2]\n",
    "\n",
    "        noisy_approx, noisy_high_freq = dwt(noisy)\n",
    "\n",
    "        noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = noisy_high_freq[0], noisy_high_freq[1] , noisy_high_freq[2]\n",
    "\n",
    "        reconstructed_prediction_image_with_high_freq_swap = idwt((noisy_approx, noisy_high_freq))\n",
    "        reconstructed_prediction_image_with_high_freq_swap = torch.transpose(reconstructed_prediction_image_with_high_freq_swap, 3, 1)\n",
    "\n",
    "\n",
    "        #denoise_high_freq = torch.transpose(torch.from_numpy(denoised_high_freq), 1, 3)\n",
    "        #denoised_noisy_approx, denoised_high_freq = dwt(denoise_high_freq.cuda())\n",
    "        #noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = denoised_high_freq[0], denoised_high_freq[1] , denoised_high_freq[2]\n",
    "\n",
    "        wavelet_high_freq_swapped = [None] * 3\n",
    "        wavelet_high_freq_swapped[0] =noisy_high_freq_fine\n",
    "        wavelet_high_freq_swapped[1] =prediction_high_freq_mid\n",
    "        wavelet_high_freq_swapped[2] =prediction_high_freq_coarse\n",
    "\n",
    "        reconstructed_prediction_image = idwt((prediction_approx,wavelet_high_freq_swapped))\n",
    "        reconstructed_prediction_image = torch.transpose(reconstructed_prediction_image, 1, 3)\n",
    "        x_model_prediction_patches.append(reconstructed_prediction_image.detach().cpu().numpy())\n",
    "    \n",
    "visualize_predictions(x_model, noisy_array,  len(noisy_array), np.concatenate(x_model_prediction_patches,axis=0), \"x_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3 : Y model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../denoising-models/mwcnn/')\n",
    "from yb_denoiser import YModel\n",
    "y_model = YModel(num_channels=4)\n",
    "y_model.load_state_dict(torch.load('../denoising-models/novel_model_weights/yb_model_203.pth'))\n",
    "y_model.eval()\n",
    "print('Model summary : ')\n",
    "print(summary(y_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction images.\n",
    "\n",
    "y_model_prediction_patches = []\n",
    "\n",
    "for img in noisy_array:\n",
    "    img_tensor = torch.unsqueeze(torch.from_numpy(img).float(), dim=0)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_tensor = y_model(img_tensor)\n",
    "        _ot = output_tensor\n",
    "        output_tensor = output_tensor.cpu().numpy()\n",
    "\n",
    "\n",
    "        _ot = torch.transpose(_ot, 1, 3)\n",
    "        noisy = torch.from_numpy(np.expand_dims(img, axis=-1).astype(np.float32)).to('cuda')\n",
    "        noisy = torch.transpose(noisy, 1, 3)\n",
    "        noisy = torch.transpose(noisy, 0, 2)\n",
    "\n",
    "        prediction_approx, prediction_high_freq = dwt(_ot.cuda())\n",
    "        prediction_high_freq_low, prediction_high_freq_mid, prediction_high_freq_coarse = prediction_high_freq[0], prediction_high_freq[1], prediction_high_freq[2]\n",
    "\n",
    "        noisy_approx, noisy_high_freq = dwt(noisy)\n",
    "\n",
    "        noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = noisy_high_freq[0], noisy_high_freq[1] , noisy_high_freq[2]\n",
    "\n",
    "        reconstructed_prediction_image_with_high_freq_swap = idwt((noisy_approx, noisy_high_freq))\n",
    "        reconstructed_prediction_image_with_high_freq_swap = torch.transpose(reconstructed_prediction_image_with_high_freq_swap, 3, 1)\n",
    "\n",
    "\n",
    "        #denoise_high_freq = torch.transpose(torch.from_numpy(denoised_high_freq), 1, 3)\n",
    "        #denoised_noisy_approx, denoised_high_freq = dwt(denoise_high_freq.cuda())\n",
    "        #noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = denoised_high_freq[0], denoised_high_freq[1] , denoised_high_freq[2]\n",
    "\n",
    "        wavelet_high_freq_swapped = [None] * 3\n",
    "        wavelet_high_freq_swapped[0] =noisy_high_freq_fine\n",
    "        wavelet_high_freq_swapped[1] =prediction_high_freq_mid\n",
    "        wavelet_high_freq_swapped[2] =prediction_high_freq_coarse\n",
    "\n",
    "        reconstructed_prediction_image = idwt((prediction_approx,wavelet_high_freq_swapped))\n",
    "        reconstructed_prediction_image = torch.transpose(reconstructed_prediction_image, 1, 3)\n",
    "        y_model_prediction_patches.append(reconstructed_prediction_image.detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "visualize_predictions(y_model, noisy_array,  len(noisy_array), np.concatenate(y_model_prediction_patches,axis=0), \"y_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 : SA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.path.append('../denoising-models/hformer_self_attention')\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "from sa_b_model import SABModel\n",
    "\n",
    "sa_model = SABModel(num_channels=4).cuda()\n",
    "sa_model.load_state_dict(torch.load('../denoising-models/novel_model_weights/sab_model_333.pth'))\n",
    "sa_model.eval()\n",
    "print('model summary\\n', summary(sa_model, input_size=(64, 64, 64, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sa_prediction_patches = []\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for i, data in enumerate(noisy_image_patches_array):\n",
    "        noisy = data\n",
    "    \n",
    "        predictions = sa_model(torch.unsqueeze(torch.from_numpy(noisy.numpy()), dim=0).to('cuda')).cpu()\n",
    "\n",
    "        sa_prediction_patches.append(predictions.detach().cpu())\n",
    "    \n",
    "sa_prediction_patches = np.concatenate(sa_prediction_patches, axis=0)\n",
    "sa_predictions = np.expand_dims(reconstruct_image_from_patches(sa_prediction_patches[0:64], 8), axis=0)\n",
    "\n",
    "\n",
    "for i in range(1, int(sa_prediction_patches.shape[0] / 64)): \n",
    "    reconstructed_image = reconstruct_image_from_patches(sa_prediction_patches[i * 64 : i * 64 + 64], num_patches_per_row=8)\n",
    "    reconstructed_image = torch.from_numpy(np.expand_dims(reconstructed_image, axis=0).astype(np.float32))\n",
    "    _ot = torch.transpose(reconstructed_image, 1, 3)\n",
    "    noisy = torch.from_numpy(np.expand_dims(noisy_array[i], axis=-1).astype(np.float32)).to('cuda')\n",
    "    noisy = torch.transpose(noisy, 1, 3)\n",
    "    noisy = torch.transpose(noisy, 0, 2)\n",
    "\n",
    "    print('ot shape : ', _ot.shape, ' noisy shape : ', noisy.shape)\n",
    "\n",
    "\n",
    "    prediction_approx, prediction_high_freq = dwt(_ot.cuda())\n",
    "    prediction_high_freq_low, prediction_high_freq_mid, prediction_high_freq_coarse = prediction_high_freq[0], prediction_high_freq[1], prediction_high_freq[2]\n",
    "\n",
    "    noisy_approx, noisy_high_freq = dwt(noisy)\n",
    "\n",
    "    noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = noisy_high_freq[0], noisy_high_freq[1] , noisy_high_freq[2]\n",
    "\n",
    "    reconstructed_prediction_image_with_high_freq_swap = idwt((noisy_approx, noisy_high_freq))\n",
    "    reconstructed_prediction_image_with_high_freq_swap = torch.transpose(reconstructed_prediction_image_with_high_freq_swap, 3, 1)\n",
    "\n",
    "\n",
    "    #denoise_high_freq = torch.transpose(torch.from_numpy(denoised_high_freq), 1, 3)\n",
    "    #denoised_noisy_approx, denoised_high_freq = dwt(denoise_high_freq.cuda())\n",
    "    #noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = denoised_high_freq[0], denoised_high_freq[1] , denoised_high_freq[2]\n",
    "\n",
    "    wavelet_high_freq_swapped = [None] * 3\n",
    "    wavelet_high_freq_swapped[0] =noisy_high_freq_fine\n",
    "    wavelet_high_freq_swapped[1] =prediction_high_freq_mid\n",
    "    wavelet_high_freq_swapped[2] =prediction_high_freq_coarse\n",
    "\n",
    "    reconstructed_prediction_image = idwt((prediction_approx,wavelet_high_freq_swapped))\n",
    "    reconstructed_prediction_image = torch.transpose(reconstructed_prediction_image, 1, 3)\n",
    "\n",
    "\n",
    "    sa_predictions= np.append(sa_predictions, reconstructed_image, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "visualize_predictions(sa_model, noisy_array,  len(noisy_array), sa_predictions, \"sa model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 : Z Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append('../denoising-models/hformer_pytorch')\n",
    "from torchinfo import summary\n",
    "\n",
    "from zb_model import ZModel \n",
    "\n",
    "z_model = ZModel(num_channels=4).cuda()\n",
    "z_model.load_state_dict(torch.load('../denoising-models/novel_model_weights/zb_model_335.pth'))\n",
    "z_model.eval()\n",
    "print('model summary\\n', summary(z_model, input_size=(64, 64, 64, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z_prediction_patches = []\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for i, data in enumerate(noisy_image_patches_array):\n",
    "        noisy = data\n",
    "    \n",
    "        predictions = z_model(torch.unsqueeze(torch.from_numpy(noisy.numpy()), dim=0).float().to('cuda')).cpu()\n",
    "\n",
    "        z_prediction_patches.append(predictions.detach().cpu())\n",
    "    \n",
    "z_prediction_patches = np.concatenate(z_prediction_patches, axis=0)\n",
    "z_predictions = np.expand_dims(reconstruct_image_from_patches(z_prediction_patches[0:64], 8), axis=0)\n",
    "\n",
    "\n",
    "for i in range(1, int(z_prediction_patches.shape[0] / 64)): \n",
    "    reconstructed_image = reconstruct_image_from_patches(z_prediction_patches[i * 64 : i * 64 + 64], num_patches_per_row=8)\n",
    "    reconstructed_image = torch.from_numpy(np.expand_dims(reconstructed_image, axis=0).astype(np.float32))\n",
    "    \n",
    "    _ot = torch.transpose(reconstructed_image, 1, 3)\n",
    "\n",
    "    noisy = torch.from_numpy(np.expand_dims(noisy_array[i], axis=-1).astype(np.float32)).to('cuda')\n",
    "    noisy = torch.transpose(noisy, 1, 3)\n",
    "    noisy = torch.transpose(noisy, 0, 2)\n",
    "\n",
    "    print('ot shape : ', _ot.shape, ' noisy shape : ', noisy.shape)\n",
    "\n",
    "\n",
    "    prediction_approx, prediction_high_freq = dwt(_ot.cuda())\n",
    "    prediction_high_freq_low, prediction_high_freq_mid, prediction_high_freq_coarse = prediction_high_freq[0], prediction_high_freq[1], prediction_high_freq[2]\n",
    "\n",
    "    noisy_approx, noisy_high_freq = dwt(noisy)\n",
    "\n",
    "    noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = noisy_high_freq[0], noisy_high_freq[1] , noisy_high_freq[2]\n",
    "\n",
    "    reconstructed_prediction_image_with_high_freq_swap = idwt((noisy_approx, noisy_high_freq))\n",
    "    reconstructed_prediction_image_with_high_freq_swap = torch.transpose(reconstructed_prediction_image_with_high_freq_swap, 3, 1)\n",
    "\n",
    "\n",
    "    #denoise_high_freq = torch.transpose(torch.from_numpy(denoised_high_freq), 1, 3)\n",
    "    #denoised_noisy_approx, denoised_high_freq = dwt(denoise_high_freq.cuda())\n",
    "    #noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = denoised_high_freq[0], denoised_high_freq[1] , denoised_high_freq[2]\n",
    "\n",
    "    wavelet_high_freq_swapped = [None] * 3\n",
    "    wavelet_high_freq_swapped[0] =noisy_high_freq_fine\n",
    "    wavelet_high_freq_swapped[1] =prediction_high_freq_mid\n",
    "    wavelet_high_freq_swapped[2] =prediction_high_freq_coarse\n",
    "\n",
    "    reconstructed_prediction_image = idwt((prediction_approx,wavelet_high_freq_swapped))\n",
    "    reconstructed_prediction_image = torch.transpose(reconstructed_prediction_image, 1, 3)\n",
    "\n",
    "\n",
    "    z_predictions= np.append(z_predictions, reconstructed_image, axis=0)\n",
    "visualize_predictions(z_model, noisy_array,  len(noisy_array), z_predictions, \"z model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 : W Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../denoising-models/hformer_pytorch')\n",
    "from torchinfo import summary\n",
    "\n",
    "from w_b_model import WModel \n",
    "\n",
    "w_model = WModel(num_channels=8).cuda()\n",
    "w_model.load_state_dict(torch.load('../denoising-models/novel_model_weights/wb_model_662.pth'))\n",
    "w_model.eval()\n",
    "print('model summary\\n', summary(w_model, input_size=(64, 64, 64, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w_prediction_patches = []\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for i, data in enumerate(noisy_image_patches_array):\n",
    "        noisy = data\n",
    "    \n",
    "        predictions = w_model(torch.unsqueeze(torch.from_numpy(noisy.numpy()), dim=0).to('cuda')).cpu()\n",
    "\n",
    "        w_prediction_patches.append(predictions.detach().cpu())\n",
    "    \n",
    "w_prediction_patches = np.concatenate(w_prediction_patches, axis=0)\n",
    "\n",
    "w_predictions = np.expand_dims(reconstruct_image_from_patches(w_prediction_patches[0:64], 8), axis=0)\n",
    "\n",
    "\n",
    "for i in range(1, int(w_prediction_patches.shape[0] / 64)): \n",
    "    reconstructed_image = reconstruct_image_from_patches(w_prediction_patches[i * 64 : i * 64 + 64], num_patches_per_row=8)\n",
    "    reconstructed_image = np.expand_dims(reconstructed_image, axis=0)\n",
    "\n",
    "    w_predictions= np.append(w_predictions, reconstructed_image, axis=0)\n",
    "\n",
    "visualize_predictions(w_model, noisy_array,  len(noisy_array), w_predictions, \"w model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet with wmodel\n",
    "\n",
    "# W model with wavelet\n",
    "from pytorch_wavelets import DTCWTForward, DTCWTInverse\n",
    "dwt = DTCWTForward(J=3).cuda()\n",
    "idwt = DTCWTInverse().cuda()\n",
    "wavelet_w_model_prediction_patches =[]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(noisy_image_patches_array.shape[0] // 64):\n",
    "        noisy = noisy_image_patches_array[i * 64 : i * 64 + 64]\n",
    "        noisy = torch.from_numpy(noisy.cpu().numpy()).to('cuda')\n",
    "        prediction = w_model(noisy)\n",
    "\n",
    "        prediction_img = torch.transpose(prediction, 1, 3)\n",
    "        transposed_noisy_image = torch.transpose(noisy, 1, 3)\n",
    "\n",
    "        prediction_approx, prediction_high_freq = dwt(prediction_img.cuda())\n",
    "        prediction_high_freq_low, prediction_high_freq_mid, prediction_high_freq_coarse = prediction_high_freq[0], prediction_high_freq[1], prediction_high_freq[2]\n",
    "\n",
    "        noisy_approx, noisy_high_freq = dwt(transposed_noisy_image.cuda())\n",
    "\n",
    "        noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = noisy_high_freq[0], noisy_high_freq[1] , noisy_high_freq[2]\n",
    "\n",
    "        reconstructed_prediction_image_with_high_freq_swap = idwt((noisy_approx, noisy_high_freq))\n",
    "        reconstructed_prediction_image_with_high_freq_swap = torch.transpose(reconstructed_prediction_image_with_high_freq_swap, 3, 1)\n",
    "\n",
    "\n",
    "        #denoise_high_freq = torch.transpose(torch.from_numpy(denoised_high_freq), 1, 3)\n",
    "        #denoised_noisy_approx, denoised_high_freq = dwt(denoise_high_freq.cuda())\n",
    "        #noisy_high_freq_fine, noisy_high_freq_mid, noisy_high_freq_coarse = denoised_high_freq[0], denoised_high_freq[1] , denoised_high_freq[2]\n",
    "\n",
    "        wavelet_high_freq_swapped = [None] * 3\n",
    "        wavelet_high_freq_swapped[0] =noisy_high_freq_fine\n",
    "        wavelet_high_freq_swapped[1] =prediction_high_freq_mid\n",
    "        wavelet_high_freq_swapped[2] =prediction_high_freq_coarse\n",
    "\n",
    "        reconstructed_prediction_image = idwt((prediction_approx,wavelet_high_freq_swapped))\n",
    "        reconstructed_prediction_image = torch.transpose(reconstructed_prediction_image, 1, 3)\n",
    "        wavelet_w_model_prediction_patches.append(reconstructed_prediction_image.detach().cpu().numpy())\n",
    "\n",
    "wavelet_w_predictions = [None] * noisy_array.shape[0]\n",
    "def reconstruct(patches,  num_images):\n",
    "    num_patches_per_image = patches.shape[0] // num_images\n",
    "    for i in range(num_images):\n",
    "        \n",
    "        image_patches = patches[i * num_patches_per_image:i * num_patches_per_image + num_patches_per_image]\n",
    "        \n",
    "        reconstruct_image = (reconstruct_image_from_patches(image_patches, 8))\n",
    "        wavelet_w_predictions[i]  = reconstruct_image\n",
    "wavelet_w_model_prediction_patches = np.concatenate(wavelet_w_model_prediction_patches)\n",
    "reconstruct(wavelet_w_model_prediction_patches, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualize_predictions(w_model, noisy_array,  len(noisy_array), wavelet_w_predictions, \"wavelet w model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V : Side by side comparison of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [\"Model\", \"PSNR\", \"SSIM\", \"MSE\"]\n",
    "\n",
    "hformer_metrics = get_average_metrics(hformer_predictions,  noisy_array)\n",
    "x_metrics= get_average_metrics(np.concatenate(x_model_prediction_patches, axis=0), noisy_array)\n",
    "y_metrics= get_average_metrics(np.concatenate(y_model_prediction_patches, axis=0),  noisy_array)\n",
    "sa_metrics = get_average_metrics(sa_predictions,  noisy_array)\n",
    "z_metrics = get_average_metrics(z_predictions,  noisy_array)\n",
    "w_metrics = get_average_metrics(w_predictions,  noisy_array)\n",
    "wavelet_w_metrics = get_average_metrics(wavelet_w_predictions, noisy_array)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pt.add_row([\"Original X-y pairs (No Model)\", '-', '-', \"-\"])\n",
    "pt.add_row([\"Hformer\",str(hformer_metrics[0]), str(hformer_metrics[1]), str(round(hformer_metrics[2], 4))])\n",
    "pt.add_row([\"X Model\",str(x_metrics[0]), str(x_metrics[1]), str(round(x_metrics[2], 4))])\n",
    "pt.add_row([\"Y Model\",str(y_metrics[0]), str(y_metrics[1]), str(round(y_metrics[2], 4))])\n",
    "pt.add_row([\"SA Model\",str(sa_metrics[0]), str(sa_metrics[1]), str(round(sa_metrics[2], 4))])\n",
    "pt.add_row([\"Z Model\",str(z_metrics[0]), str(z_metrics[1]), str(round(z_metrics[2], 4))])\n",
    "pt.add_row([\"W Model\",str(w_metrics[0]), str(w_metrics[1]), str(round(w_metrics[2], 4))])\n",
    "pt.add_row([\"W Wavelet Model\",str(wavelet_w_metrics[0]), str(wavelet_w_metrics[1]), str(round(wavelet_w_metrics[2], 4))])\n",
    "\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 : Output of predictions of all 4 models side by side for direct visualize comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions_all_models(X_test,  n, hformer_predictions, x_predictions, y_predictions, sa_predictions, z_predictions, w_predictions, wavelet_w_predictions):\n",
    "    random_numbers = list(range(n))  # not very random\n",
    "    for i in random_numbers:\n",
    "        gt_image= X_test[i]\n",
    "\n",
    "        hformer_pred = hformer_predictions[i]\n",
    "        x_pred = x_predictions[i]\n",
    "        y_pred = y_predictions[i]\n",
    "        sa_pred = sa_predictions[i]\n",
    "        z_pred = z_predictions[i]\n",
    "        w_pred = w_predictions[i]\n",
    "        wavelet_w_pred = wavelet_w_predictions[i]\n",
    "\n",
    "        models = [\"HFORMER\", \"X\", \"Y\", \"SA\",  \"Z\", \"W\", \"Wavelet W\"]\n",
    "        predictions = [hformer_pred, x_pred, y_pred, sa_pred, z_pred, w_pred, wavelet_w_pred]\n",
    "\n",
    "        # Display QD and FD images\n",
    "        f, axarr = plt.subplots(1, 1 + len(models), figsize=(41,41))\n",
    "\n",
    "\n",
    "\n",
    "        axarr[0].imshow(trunc(denormalize(gt_image)), cmap='gray', vmin=-160.0, vmax=240.0)\n",
    "        axarr[0].set_title(\"FD Image\")\n",
    "        axarr[0].set_axis_off()\n",
    "\n",
    "        for j, (model_name, predicted_image) in enumerate(zip(models, predictions), start=1):\n",
    "            if predicted_image.shape[-1] == 3:\n",
    "                predicted_image = rgb2gray(predicted_image)\n",
    "\n",
    "            psnr_recon = calculate_psnr(trunc(denormalize(gt_image)), trunc(denormalize(predicted_image)))\n",
    "            ssim_recon = calculate_ssim(trunc(denormalize(gt_image)), trunc(denormalize(predicted_image)))\n",
    "            rmse_recon = calculate_rmse(trunc(denormalize(gt_image)), trunc(denormalize(predicted_image)))\n",
    "\n",
    "            psnr_recon = round(psnr_recon, 4)\n",
    "            ssim_recon = round(ssim_recon, 4)\n",
    "            mse_recon = round(rmse_recon, 4)\n",
    "\n",
    "            axarr[j].imshow(trunc(denormalize(predicted_image)), cmap='gray', vmin=-160.0, vmax=240.0)\n",
    "            axarr[j].set_title(\"{}\\nPSNR={}\\nSSIM={}\\nMSE={}\".format(model_name, psnr_recon, ssim_recon, mse_recon))\n",
    "            axarr[j].set_axis_off()\n",
    "\n",
    "        plt.savefig('../../output/lodopab_ct_wavelet_b_models/combined_outputs_image_index_{}.png'.format(i))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "visualize_predictions_all_models(noisy_array,  len(noisy_array), hformer_predictions, np.concatenate(x_model_prediction_patches, axis=0), np.concatenate(y_model_prediction_patches, axis=0), sa_predictions, z_predictions, w_predictions, wavelet_w_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denoising-conda-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
